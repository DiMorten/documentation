%%%% This file includes the introduction %%%%

\section{Introduction}

Agriculture must strongly increase its production to feed the nine-billion people predicted by mid-century, while minimizing its environmental impact. In this context the demand for efficient, comprehensive and precise agriculture intelligence has seen an important increase during past years. In particular, crop production information can be used to develop commercial plans, regulate internal stocks and to perform customized management decisions \cite{leite2011hidden}. Remote sensing imagery has increasingly been used for this task because it is a cost-efficient means for gathering timely, detailed and reliable information over large areas with short revisit periods \cite{thenkabail2015land}.

Crop recognition is challenging because some fields are covered with different types of crops during the year and such practice may be influenced by multiple reasons including phenological, ecologic or economic changes. Thus, agricultural areas are characterized by their temporal dynamics as well as their typical spatial patterns \cite{lohmann2008multi}. 
%waske2009classifier
A commonly used method consists of stacking the multi-temporal sequence of images together and training a classifier using information from each individual pixel, neglecting any spatial relationship among neighboring pixels. Probabilistic graphical models such as Conditional Random Fields are able to capture spatio-temporal context and have been used for crop recognition \cite{achanccaray2017spatial}, however it is necessary to study and select what kind of hand-crafted features should be employed. 

In recent years, deep learning models have made breakthroughs in several fields such as speech recognition and computer vision \cite{lecun2015deep}. In the field of remote sensing, these models have become a powerful tool to solve challenging tasks achieving state-of-the-art results in different applications \cite{audebertdeep}. In particular, Recurrent Neural Networks (RNN) are designed to handle data from temporal sequences while Convolutional Neural Networks (CNN) are useful for understanding spatial context. 

In \cite{rnnjose}, a RNN is used for crop recognition, where at each time step, a convolutional layer is applied to each image from the sequence. LSTM is a particular type of RNN which has achieved performance improvements over its basic model \cite{mou2018learning}. As a combination of previous ideas, convolutional LSTM networks (ConvLSTM) are designed to model both spatial and temporal context by replacing the LSTM input-to-state and state-to-state layers with convolutions \cite{xingjian2015convolutional}. On the other hand, Fully Convolutional Networks (FCN) have become state-of-the-art in semantic segmentation tasks while improving inference time \cite{long2015fully}. In \cite{fcnlaura} a FCN was applied for the multi-temporal crop recognition task with SAR images.

This work fits in this context aiming to assess some of the most successful deep learning architectures for multi-temporal crop recognition: FCNs, LSTMs and ConvLSTMs. %Besides, it proposes a new architecture based on the ConvLSTM cell. 
In \cite{russwurm2018multi}, a convolutional RNN is used for crop recognition, but is based on optimal images and it is only evaluated in a temperate climate. Additionally, we include a commonly used image stacking approach as a baseline. The experiments were conducted over two study areas with very different weather conditions: the first is located in Hanover, Germany with a temperate climate; while the second one corresponds to a sub-tropical region in Campo Verde municipality, Brazil. To the best of our knowledge, this is the first time a ConvLSTM is used for multitemporal crop recognition in a sub-tropical region.

The remainder of this paper is organized as follows: Section II explains the concepts of LSTM, ConvLSTM and FCN. Section III describes the assessed architectures for crop recognition. In section IV, the study areas and the experimental protocol are presented. Then, results are discussed in Section V. Finally, conclusions are summarized in Section VI.
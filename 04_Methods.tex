%%%% This file includes the material and methods %%%%
\section{Methods}

This section describes the proposed methods for crop recognition, based on LSTM and FCN as well as the traditional image stacking \cite{schneider2012monitoring,schneider2008compact} approach for multitemporal classification, which was used as a baseline.

\subsection{Image stacking (IS)}

This method consists of computing hand-crafted features for each image in the multitemporal sequence and stacking them all together, obtaining a feature vector from each pixel location. The resulting representation is then used to train a classification algorithm that assigns a class label for a given pixel. 

\subsection{LSTM for patch classification (LSTM-PC)}

Following \cite{rnnjose}, an LSTM-based architecture for patch classification was designed (LSTM-PC). We chose to work with the original bands, because it achieved slightly better results than using the GLCM attributes in preliminary experiments. Patches of $(time, w, w, channels)$ size were extracted from the original image and flattened into a sequence of feature vectors with dimensions $(time, w*w*channels)$. 

At first, the sequence is passed through a basic LSTM cell. Then, the cell's last output is gathered and passed to a FC layer. Finally, a softmax layer produces the output class probabilities. In each case, the predicted class is assigned to the input's central pixel and the inferred image is constructed by spatially concatenating the classification results. \vspace{0.5cm}
% This architecture is shown in Table \ref{table:lstm}.
\begin{table}[h!]
\centering
\caption{LSTM-PC network architecture. Output sizes are described in number of filters. In Campo Verde, class number is specific to each sequence}
\label{table:lstm}
\begin{tabular}{|c|c|c|}
\hline
\multicolumn{1}{|l|}{} & \multicolumn{2}{c|}{\textbf{Output Size}} \\ \hline
\textbf{Layer} & \textbf{Campo Verde} & \textbf{Hanover} \\ \hline
\textbf{LSTM} & $100$ & $100$ \\ \hline
\textbf{FC} & $100$ & $300$ \\ \hline
\textbf{Softmax} & $10$ or $9$ & $8$ \\ \hline
\end{tabular}
\end{table}

\subsection{ConvLSTM for patch classification (ConvLSTM-PC)}

Similarly to LSTM-PC, the ConvLSTM cell takes patches extracted from each image in a multi-temporal sequence as input. Input dimensions are $(time, w, w, channels)$, which are passed through a ConvLSTM cell. Then, the sequence's last image is selected and \textit{max. pooling} is applied. The result is flattened and taken to FC and softmax layers. As with the previous model, resulting classification is assigned to the central pixel of each patch.
\vspace{0.5cm}

% ConvLSTM-PC architecture is shown in Table \ref{table:convlstm}.


\begin{table}[h!]
\centering
\caption{ConvLSTM-PC network architecture. Output sizes are described in $(rows\times cols\times filters)$ or number of filters}
\label{table:convlstm}
\begin{tabular}{|c|c|c|}
\hline
\multicolumn{1}{|l|}{} & \multicolumn{2}{c|}{\textbf{Output Size}}     \\ \hline
\textbf{Layer}         & \textbf{Campo Verde}   & \textbf{Hanover}     \\ \hline
\textbf{ConvLSTM}      & $15\times 15\times 16$ & $5\times 5\times 16$ \\ \hline
\textbf{Max. Pool}     & $7\times 7\times 16$   & -                    \\ \hline
\textbf{FC}          & $100$                  & $300$                \\ \hline
\textbf{Softmax}       & $10$ or $9$              & $8$                  \\ \hline
\end{tabular}
\end{table}



\subsection{FCN for patch labeling (FCN-PL)}

The input for the FCN-PL is a stack of all images in a multi-temporal sequence with shape as $(w, w, channels*time steps)$. The fully convolutional DenseNet architecture was used. The network is called full patch labeling as the output of the network is the set of labels of the whole patch and not only the central pixel. At inference, outputs are spatially concatenated to form the final image mosaic.

 
%and are implemented with \textit{average pooling} and \textit{transpose convolution} operations respectively.
